{"cells":[{"source":"# ============================================================================\n# 02. RFM SEGMENTATION & CLV ANALYSIS\n# Business question: Who are my best customers and which are at risk?\n# ============================================================================\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Format\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.float_format', '{:.2f}'.format)\n\n# ============================================================================\n## 1. DATA LOADING\n# ============================================================================\n\nretail_clean = pd.read_csv('online_retail_clean.csv', parse_dates=['InvoiceDate'])\n\nprint('='*70)\nprint('RFM SEGMENTATION & CLV ANALYSIS')\nprint('='*70)\n\nprint(f'\\nDataset: {len(retail_clean):,} transactions')\nprint(f'Unique Customers: {retail_clean[\"CustomerID\"].nunique():,}')\nprint(f'Date range: {retail_clean[\"InvoiceDate\"].min().date()} to {retail_clean[\"InvoiceDate\"].max().date()}')\n\n# Reference date for Recency calculation (last date + 1 day)\nreference_date = retail_clean['InvoiceDate'].max() + pd.Timedelta(days=1)\nprint(f'Reference date (for Recency): {reference_date.date()}')\n\n# ============================================================================\n## 2. RFM CALCULATION (Customer-Level Metrics)\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('CALCULATING RFM METRICS')\nprint('='*70)\n\n# Calculate RFM at customer level\nrfm_data = retail_clean.groupby('CustomerID').agg({\n    'InvoiceDate': lambda x: (reference_date - x.max()).days,  # Recency\n    'InvoiceNo': 'nunique',                                     # Frequency\n    'Revenue': 'sum'                                            # Monetary\n}).reset_index()\n\nrfm_data.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n\n# Remove negative Monetary (returns only)\nrfm_data = rfm_data[rfm_data['Monetary'] > 0]\n\nprint(f'\\nCustomers analyzed: {len(rfm_data):,}')\nprint('\\n=== RFM RAW METRICS (Sample) ===')\nprint(rfm_data.head(10))\n\nprint('\\n=== RFM DESCRIPTIVE STATS ===')\nprint(rfm_data[['Recency', 'Frequency', 'Monetary']].describe())\n\n# ============================================================================\n## 3. RFM SCORING (Percentile-Based)\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('RFM SCORING (Percentile-Based)')\nprint('='*70)\n\n# Recency Score (INVERTED: lower recency = better = higher score)\nrfm_data['R_score'] = pd.cut(\n    rfm_data['Recency'],\n    bins=[0, \n          rfm_data['Recency'].quantile(0.2),\n          rfm_data['Recency'].quantile(0.4),\n          rfm_data['Recency'].quantile(0.6),\n          rfm_data['Recency'].quantile(0.8),\n          rfm_data['Recency'].max()],\n    labels=[5, 4, 3, 2, 1],\n    include_lowest=True\n)\n\n# Frequency Score (higher frequency = better = higher score)\nrfm_data['F_score'] = pd.cut(\n    rfm_data['Frequency'],\n    bins=[0,\n          rfm_data['Frequency'].quantile(0.2),\n          rfm_data['Frequency'].quantile(0.4),\n          rfm_data['Frequency'].quantile(0.6),\n          rfm_data['Frequency'].quantile(0.8),\n          rfm_data['Frequency'].max()],\n    labels=[1, 2, 3, 4, 5],\n    include_lowest=True,\n    duplicates='drop'\n)\n\n# Monetary Score (higher monetary = better = higher score)\nrfm_data['M_score'] = pd.cut(\n    rfm_data['Monetary'],\n    bins=[0,\n          rfm_data['Monetary'].quantile(0.2),\n          rfm_data['Monetary'].quantile(0.4),\n          rfm_data['Monetary'].quantile(0.6),\n          rfm_data['Monetary'].quantile(0.8),\n          rfm_data['Monetary'].max()],\n    labels=[1, 2, 3, 4, 5],\n    include_lowest=True,\n    duplicates='drop'\n)\n\n# Fill NaN (if any due to duplicates) with median score\nrfm_data['R_score'] = rfm_data['R_score'].fillna(3)\nrfm_data['F_score'] = rfm_data['F_score'].fillna(3)\nrfm_data['M_score'] = rfm_data['M_score'].fillna(3)\n\n# Convert to int\nrfm_data['R_score'] = rfm_data['R_score'].astype(int)\nrfm_data['F_score'] = rfm_data['F_score'].astype(int)\nrfm_data['M_score'] = rfm_data['M_score'].astype(int)\n\nprint('\\n=== RFM SCORE DISTRIBUTION ===')\nprint(f\"\\nRecency Score (5=recent, 1=old):\")\nprint(rfm_data['R_score'].value_counts().sort_index())\n\nprint(f\"\\nFrequency Score (5=frequent, 1=rare):\")\nprint(rfm_data['F_score'].value_counts().sort_index())\n\nprint(f\"\\nMonetary Score (5=high spend, 1=low):\")\nprint(rfm_data['M_score'].value_counts().sort_index())\n\n# Validate scoring makes sense\nprint('\\n=== SCORING VALIDATION ===')\nprint('\\nAverage Raw Metrics by Score:')\nfor score in [1, 2, 3, 4, 5]:\n    r_avg = rfm_data[rfm_data['R_score']==score]['Recency'].mean()\n    f_avg = rfm_data[rfm_data['F_score']==score]['Frequency'].mean()\n    m_avg = rfm_data[rfm_data['M_score']==score]['Monetary'].mean()\n    print(f'\\nScore {score}:')\n    print(f'  Avg Recency: {r_avg:.0f} days')\n    print(f'  Avg Frequency: {f_avg:.1f} orders')\n    print(f'  Avg Monetary: â‚¬{m_avg:,.0f}')\n\n# ============================================================================\n## 4. RFM SEGMENTATION (Business Labels)\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('RFM SEGMENTATION')\nprint('='*70)\n\ndef rfm_segment(row):\n    \"\"\"\n    RFM Segmentation based on industry best practices.\n    \n    Segments:\n    - Champions: Best customers (Râ‰¥4, Fâ‰¥4, Mâ‰¥4)\n    - Loyal: Frequent buyers with good spend (Fâ‰¥4, Mâ‰¥3)\n    - Potential: Good prospects (Râ‰¥3, Fâ‰¥2, Mâ‰¥3)\n    - At-Risk: Good history but recently inactive (Râ‰¤2, Fâ‰¥3)\n    - New: Recent first purchase (Râ‰¥4, F=1)\n    - Lost: Inactive across all metrics (catch-all)\n    \"\"\"\n    R = row['R_score']\n    F = row['F_score']\n    M = row['M_score']\n    \n    if R >= 4 and F >= 4 and M >= 4:\n        return 'Champions'\n    elif F >= 4 and M >= 3:\n        return 'Loyal'\n    elif R >= 3 and F >= 2 and M >= 3:\n        return 'Potential'\n    elif R <= 2 and F >= 3:\n        return 'At-Risk'\n    elif R >= 4 and F == 1:\n        return 'New'\n    else:\n        return 'Lost'\n\n# Apply segmentation\nrfm_data['Segment'] = rfm_data.apply(rfm_segment, axis=1)\n\n# Segment distribution\nprint('\\n=== SEGMENT DISTRIBUTION ===')\nsegment_dist = rfm_data['Segment'].value_counts()\nsegment_pct = (segment_dist / len(rfm_data) * 100).round(1)\nsegment_summary = pd.DataFrame({\n    'Count': segment_dist,\n    'Percentage': segment_pct.apply(lambda x: f'{x}%')\n})\nprint(segment_summary)\n\n# Segment validation (check if logic makes sense)\nprint('\\n=== SEGMENT PROFILE (Average Metrics) ===')\nsegment_profile = rfm_data.groupby('Segment').agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'Monetary': 'mean',\n    'CustomerID': 'count'\n}).rename(columns={'CustomerID': 'Count'}).round(1)\nprint(segment_profile.sort_values('Monetary', ascending=False))\n\n# ============================================================================\n## 5. CLV ANALYSIS BY SEGMENT\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('CLV ANALYSIS BY SEGMENT')\nprint('='*70)\n\n# Calculate CLV metrics\nrfm_data['CLV'] = rfm_data['Monetary']  # Simple CLV = total historical spend\nrfm_data['AOV'] = rfm_data['Monetary'] / rfm_data['Frequency']\n\n# CLV by segment\nclv_by_segment = rfm_data.groupby('Segment').agg({\n    'CLV': ['mean', 'median', 'sum'],\n    'AOV': 'mean',\n    'Frequency': 'mean',\n    'CustomerID': 'count'\n}).round(2)\n\nclv_by_segment.columns = ['Avg_CLV', 'Median_CLV', 'Total_CLV', 'Avg_AOV', 'Avg_Frequency', 'Count']\nclv_by_segment = clv_by_segment.sort_values('Total_CLV', ascending=False)\n\nprint(clv_by_segment)\n\n# Revenue concentration\ntotal_revenue = rfm_data['CLV'].sum()\nclv_by_segment['Revenue_Share'] = (clv_by_segment['Total_CLV'] / total_revenue * 100).round(1)\n\nprint('\\n=== REVENUE CONCENTRATION ===')\nprint(clv_by_segment[['Count', 'Total_CLV', 'Revenue_Share']])\n\n# Pareto principle check\nchampions_revenue_share = clv_by_segment.loc['Champions', 'Revenue_Share']\nchampions_customer_share = (clv_by_segment.loc['Champions', 'Count'] / len(rfm_data) * 100).round(1)\n\nprint(f'\\nðŸ“Š PARETO ANALYSIS:')\nprint(f'   Champions represent {champions_customer_share}% of customers')\nprint(f'   but generate {champions_revenue_share}% of revenue')\n\n# ============================================================================\n## 6. VISUALIZATION: RFM SCORES & SEGMENTS\n# ============================================================================\n\n# 6A: RFM Score Distribution\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Recency\nsns.countplot(data=rfm_data, x='R_score', ax=axes[0], palette='RdYlGn')\naxes[0].set_title('Recency Score Distribution', fontsize=12, fontweight='bold')\naxes[0].set_xlabel('Recency Score (5=Recent)')\naxes[0].bar_label(axes[0].containers[0])\n\n# Frequency\nsns.countplot(data=rfm_data, x='F_score', ax=axes[1], palette='Blues')\naxes[1].set_title('Frequency Score Distribution', fontsize=12, fontweight='bold')\naxes[1].set_xlabel('Frequency Score (5=Frequent)')\naxes[1].bar_label(axes[1].containers[0])\n\n# Monetary\nsns.countplot(data=rfm_data, x='M_score', ax=axes[2], palette='Greens')\naxes[2].set_title('Monetary Score Distribution', fontsize=12, fontweight='bold')\naxes[2].set_xlabel('Monetary Score (5=High Spend)')\naxes[2].bar_label(axes[2].containers[0])\n\nplt.tight_layout()\nplt.show()\n\n# 6B: Segment Distribution\nfig, ax = plt.subplots(figsize=(10, 6))\nsegment_order = clv_by_segment.sort_values('Total_CLV', ascending=True).index\nsns.barplot(\n    data=rfm_data, \n    y='Segment', \n    x='CLV',\n    order=segment_order,\n    estimator=sum,\n    palette='viridis',\n    ax=ax\n)\nax.set_title('Total Revenue by Segment', fontsize=14, fontweight='bold')\nax.set_xlabel('Total CLV (â‚¬)', fontsize=12)\nax.set_ylabel('Segment', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n## 7. CONNECTION TO NOTEBOOK 01 (Cohort Analysis)\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('CONNECTION TO COHORT ANALYSIS')\nprint('='*70)\n\n# Load first_purchase data from Notebook 01\nfirst_purchase = (\n    retail_clean.groupby('CustomerID')['InvoiceDate']\n    .min()\n    .reset_index()\n    .rename(columns={'InvoiceDate': 'first_purchase_date'})\n)\nfirst_purchase['cohort'] = first_purchase['first_purchase_date'].dt.to_period('M').astype(str)\n\n# Merge with RFM data\nrfm_cohort = rfm_data.merge(first_purchase[['CustomerID', 'cohort']], on='CustomerID', how='left')\n\n# Compare 2010-12 vs rest\ncohort_2010_12 = rfm_cohort[rfm_cohort['cohort'] == '2010-12']\nrest_cohorts = rfm_cohort[rfm_cohort['cohort'] > '2010-12']\n\nprint('\\n=== SEGMENT DISTRIBUTION BY COHORT ===')\nprint('\\n2010-12 Cohort:')\nprint(cohort_2010_12['Segment'].value_counts(normalize=True).mul(100).round(1))\n\nprint('\\nRest Cohorts:')\nprint(rest_cohorts['Segment'].value_counts(normalize=True).mul(100).round(1))\n\n# Champions rate comparison\nchampions_2010_12 = (cohort_2010_12['Segment'] == 'Champions').mean() * 100\nchampions_rest = (rest_cohorts['Segment'] == 'Champions').mean() * 100\n\nprint(f'\\nâœ… KEY FINDING:')\nprint(f'   2010-12 cohort has {champions_2010_12:.1f}% Champions')\nprint(f'   Rest cohorts have {champions_rest:.1f}% Champions')\nprint(f'   Difference: {champions_2010_12 - champions_rest:+.1f}pp')\nprint(f'\\n   â†’ Confirms Notebook 01 finding: First cohort has superior cust')\nrfm_data.to_csv('rfm_segments.csv', index=False)\n","metadata":{},"cell_type":"code","id":"f624187a-a869-48ed-83a6-6e27b1136e19","outputs":[],"execution_count":null}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (User venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}