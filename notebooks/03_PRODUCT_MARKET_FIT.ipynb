{"cells":[{"source":"# ============================================================================\n# 03. PRODUCT-MARKET FIT ANALYSIS\n# Business question: Which products drive retention and high-value customers?\n# ============================================================================\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Format\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.float_format', '{:.2f}'.format)\n\n# ============================================================================\n## 1. DATA LOADING & PREPARATION\n# ============================================================================\n\nprint('='*70)\nprint('PRODUCT-MARKET FIT ANALYSIS')\nprint('='*70)\n\n# Load clean data\nretail_clean = pd.read_csv('online_retail_clean.csv', parse_dates=['InvoiceDate'])\n\nprint(f'\\nDataset: {len(retail_clean):,} transactions')\nprint(f'Unique Customers: {retail_clean[\"CustomerID\"].nunique():,}')\nprint(f'Unique Products: {retail_clean[\"StockCode\"].nunique():,}')\nprint(f'Date range: {retail_clean[\"InvoiceDate\"].min().date()} to {retail_clean[\"InvoiceDate\"].max().date()}')\n\n# Load RFM segments from Notebook 02\ntry:\n    rfm_segments = pd.read_csv('rfm_segments.csv')\n    print(f'\\nâœ… Loaded RFM segments: {len(rfm_segments):,} customers')\nexcept FileNotFoundError:\n    print('\\nâš ï¸ RFM segments file not found. Recalculating...')\n    reference_date = retail_clean['InvoiceDate'].max() + pd.Timedelta(days=1)\n    rfm_segments = retail_clean.groupby('CustomerID').agg({\n        'InvoiceDate': lambda x: (reference_date - x.max()).days,\n        'InvoiceNo': 'nunique',\n        'Revenue': 'sum'\n    }).reset_index()\n    rfm_segments.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n    rfm_segments = rfm_segments[rfm_segments['Monetary'] > 0]\n    \n    rfm_segments['R_score'] = pd.cut(rfm_segments['Recency'], bins=5, labels=[5,4,3,2,1])\n    rfm_segments['F_score'] = pd.cut(rfm_segments['Frequency'], bins=5, labels=[1,2,3,4,5])\n    rfm_segments['M_score'] = pd.cut(rfm_segments['Monetary'], bins=5, labels=[1,2,3,4,5])\n    rfm_segments['R_score'] = rfm_segments['R_score'].astype(int)\n    rfm_segments['F_score'] = rfm_segments['F_score'].astype(int)\n    rfm_segments['M_score'] = rfm_segments['M_score'].astype(int)\n    \n    def rfm_segment(row):\n        R, F, M = row['R_score'], row['F_score'], row['M_score']\n        if R >= 4 and F >= 4 and M >= 4:\n            return 'Champions'\n        elif F >= 4 and M >= 3:\n            return 'Loyal'\n        elif R >= 3 and F >= 2 and M >= 3:\n            return 'Potential'\n        elif R <= 2 and F >= 3:\n            return 'At-Risk'\n        elif R >= 4 and F == 1:\n            return 'New'\n        else:\n            return 'Lost'\n    \n    rfm_segments['Segment'] = rfm_segments.apply(rfm_segment, axis=1)\n    rfm_segments['CLV'] = rfm_segments['Monetary']\n\n# Customer-level metrics\ncustomer_metrics = retail_clean.groupby('CustomerID').agg({\n    'InvoiceNo': 'nunique',\n    'InvoiceDate': ['min', 'max']\n}).reset_index()\ncustomer_metrics.columns = ['CustomerID', 'Frequency', 'First_Purchase', 'Last_Purchase']\ncustomer_metrics['Is_Repeat'] = customer_metrics['Frequency'] > 1\n\nprint(f'\\nTotal customers: {len(customer_metrics):,}')\nprint(f'Repeat customers: {customer_metrics[\"Is_Repeat\"].sum():,} ({customer_metrics[\"Is_Repeat\"].mean()*100:.1f}%)')\nprint(f'One-time customers: {(~customer_metrics[\"Is_Repeat\"]).sum():,} ({(~customer_metrics[\"Is_Repeat\"]).mean()*100:.1f}%)')\n\n# Merge for analysis\nretail_analysis = retail_clean.merge(customer_metrics, on='CustomerID', how='left')\n\n# ============================================================================\n## 2. FIRST PURCHASE PRODUCTS: Repeat vs One-Time Customers\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('FIRST PURCHASE ANALYSIS')\nprint('='*70)\n\nretail_analysis['Purchase_Rank'] = (\n    retail_analysis.groupby('CustomerID')['InvoiceDate']\n    .rank(method='dense')\n)\nfirst_purchases = retail_analysis[retail_analysis['Purchase_Rank'] == 1]\n\nrepeat_first = (\n    first_purchases[first_purchases['Is_Repeat']]\n    .groupby('Description')\n    .size()\n    .sort_values(ascending=False)\n    .head(10)\n)\n\nonetime_first = (\n    first_purchases[~first_purchases['Is_Repeat']]\n    .groupby('Description')\n    .size()\n    .sort_values(ascending=False)\n    .head(10)\n)\n\nprint('\\n=== TOP 10: First Purchase Products (Repeat Customers) ===')\nprint(repeat_first)\n\nprint('\\n=== TOP 10: First Purchase Products (One-Time Customers) ===')\nprint(onetime_first)\n\nrepeat_set = set(repeat_first.index)\nonetime_set = set(onetime_first.index)\noverlap = repeat_set.intersection(onetime_set)\n\nprint(f'\\nðŸ“Š OVERLAP: {len(overlap)} products appear in both Top 10 lists')\nif overlap:\n    print(f'   Common products: {list(overlap)[:3]}...')\n\n# ============================================================================\n## 3. REPURCHASE RATE BY PRODUCT\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('PRODUCT REPURCHASE ANALYSIS')\nprint('='*70)\n\nproduct_first_buyers = (\n    first_purchases.groupby('Description')['CustomerID']\n    .nunique()\n    .rename('first_buyers')\n)\n\nrepeat_buyers = (\n    first_purchases[first_purchases['Is_Repeat']]\n    .groupby('Description')['CustomerID']\n    .nunique()\n    .rename('repeat_buyers')\n)\n\nrepurchase_analysis = pd.concat([product_first_buyers, repeat_buyers], axis=1).fillna(0)\nrepurchase_analysis['repurchase_rate'] = (\n    repurchase_analysis['repeat_buyers'] / repurchase_analysis['first_buyers'] * 100\n).round(2)\n\nrepurchase_filtered = repurchase_analysis[repurchase_analysis['first_buyers'] >= 20]\nrepurchase_filtered = repurchase_filtered.sort_values('repurchase_rate', ascending=False)\n\nprint(f'\\nProducts analyzed: {len(repurchase_analysis):,}')\nprint(f'Products with â‰¥20 first buyers: {len(repurchase_filtered):,}')\n\nprint('\\n=== TOP 10: Highest Repurchase Rate (min 20 buyers) ===')\nprint(repurchase_filtered.head(10))\n\nprint('\\n=== BOTTOM 10: Lowest Repurchase Rate (min 20 buyers) ===')\nprint(repurchase_filtered.tail(10))\n\n# ============================================================================\n## 4. PRODUCT Ã— SEGMENT INSIGHT (CLV USE ONLY FOR PROFILE)\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('PRODUCT PURCHASE BY CUSTOMER SEGMENT')\nprint('='*70)\n\nproduct_clv = retail_analysis.merge(\n    rfm_segments[['CustomerID', 'CLV', 'Segment']], \n    on='CustomerID', \n    how='left'\n)\n\nchampions_products = (\n    product_clv[product_clv['Segment'] == 'Champions']\n    .groupby('Description')\n    .size()\n    .sort_values(ascending=False)\n    .head(10)\n)\n\natrisk_products = (\n    product_clv[product_clv['Segment'] == 'At-Risk']\n    .groupby('Description')\n    .size()\n    .sort_values(ascending=False)\n    .head(10)\n)\n\nprint('\\n=== TOP 10: Products Bought by CHAMPIONS ===')\nprint(champions_products)\n\nprint('\\n=== TOP 10: Products Bought by AT-RISK ===')\nprint(atrisk_products)\n\nchamp_set = set(champions_products.index)\natrisk_set = set(atrisk_products.index)\noverlap_segments = champ_set.intersection(atrisk_set)\n\nprint(f'\\nðŸ“Š PRODUCT DIFFERENTIATION:')\nprint(f'   Champions-only products: {len(champ_set - atrisk_set)}')\nprint(f'   At-Risk-only products: {len(atrisk_set - champ_set)}')\nprint(f'   Shared products: {len(overlap_segments)}')\n\n# ============================================================================\n## 5. HERO PRODUCTS (REVENUE Ã— REPURCHASE RATE)\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('HERO PRODUCTS IDENTIFICATION (Revenue-based)')\nprint('='*70)\n\nproduct_stats = (\n    retail_clean\n    .groupby('Description')\n    .agg({\n        'Revenue': 'sum',\n        'CustomerID': 'nunique'\n    })\n    .reset_index()\n    .rename(columns={\n        'Revenue': 'Product_Revenue',\n        'CustomerID': 'Unique_Customers'\n    })\n)\n\nproduct_analysis = product_stats.merge(\n    repurchase_filtered[['first_buyers', 'repeat_buyers', 'repurchase_rate']],\n    on='Description',\n    how='left'\n)\n\nmin_customers = 50\nmin_first_buyers = 20\n\nproduct_analysis_filtered = product_analysis[\n    (product_analysis['Unique_Customers'] >= min_customers) &\n    (product_analysis['first_buyers'] >= min_first_buyers)\n].copy()\n\nprint(f\"\\nProducts with â‰¥{min_customers} customers and â‰¥{min_first_buyers} first buyers: {len(product_analysis_filtered):,}\")\n\nproduct_analysis_filtered['Hero_Score'] = (\n    product_analysis_filtered['Product_Revenue'] *\n    (product_analysis_filtered['repurchase_rate'] / 100)\n)\n\nhero_products = (\n    product_analysis_filtered\n    .sort_values('Hero_Score', ascending=False)\n    .head(15)\n)\n\nprint('\\n=== TOP 15 HERO PRODUCTS (Revenue Ã— Repurchase Rate) ===')\nprint(\n    hero_products[[\n        'Description',\n        'Product_Revenue',\n        'Unique_Customers',\n        'first_buyers',\n        'repurchase_rate',\n        'Hero_Score'\n    ]]\n)\n\nhero_revenue = hero_products['Product_Revenue'].sum()\ntotal_revenue = retail_clean['Revenue'].sum()\nhero_pct = hero_revenue / total_revenue * 100\n\nprint('\\n=== HERO PRODUCTS REVENUE CONTRIBUTION ===')\nprint(f\"Total revenue (clean dataset): â‚¬{total_revenue:,.2f}\")\nprint(f\"Hero products revenue:         â‚¬{hero_revenue:,.2f}\")\nprint(f\"Hero products share:           {hero_pct:.1f}%\")\nprint(f\"Average hero repurchase rate:  {hero_products['repurchase_rate'].mean():.1f}%\")\n\n# ============================================================================\n## 6. VISUALIZATION\n# ============================================================================\n\n# 6A: Scatter Plot - Repurchase Rate vs Product Revenue\nfig, ax = plt.subplots(figsize=(12, 7))\nscatter_data = product_analysis_filtered.copy()\n\nsns.scatterplot(\n    data=scatter_data,\n    x='repurchase_rate',\n    y='Product_Revenue',\n    size='Unique_Customers',\n    sizes=(50, 800),\n    alpha=0.6,\n    ax=ax\n)\n\nmedian_repurchase = scatter_data['repurchase_rate'].median()\nmedian_revenue = scatter_data['Product_Revenue'].median()\nax.axvline(x=median_repurchase, color='red', linestyle='--', linewidth=1, alpha=0.7)\nax.axhline(y=median_revenue, color='red', linestyle='--', linewidth=1, alpha=0.7)\n\nfor idx, row in hero_products.head(5).iterrows():\n    ax.annotate(\n        row['Description'][:20] + '...',\n        xy=(row['repurchase_rate'], row['Product_Revenue']),\n        fontsize=8,\n        alpha=0.7\n    )\n\nax.set_xlabel('Repurchase Rate (%)', fontsize=12)\nax.set_ylabel('Product Revenue (â‚¬)', fontsize=12)\nax.set_title('Product Performance: Revenue vs Repurchase Rate', fontsize=14, fontweight='bold')\nplt.legend(loc='upper left', title='Unique Customers')\nplt.tight_layout()\nplt.show()\n\n# 6B: Bar Plot - Hero Products\nfig, ax = plt.subplots(figsize=(12, 8))\nhero_plot = hero_products.sort_values('Hero_Score', ascending=True)\n\nax.barh(\n    hero_plot['Description'].str.slice(0, 40),\n    hero_plot['Hero_Score'],\n    color='steelblue'\n)\nax.set_xlabel('Hero Score (Revenue Ã— Repurchase Rate)', fontsize=12)\nax.set_title('Top 15 Hero Products', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n## 7. CONNECTION TO PREVIOUS NOTEBOOKS\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('CROSS-NOTEBOOK INSIGHTS')\nprint('='*70)\n\nfirst_purchase_dates = retail_clean.groupby('CustomerID')['InvoiceDate'].min().reset_index()\nfirst_purchase_dates['cohort'] = first_purchase_dates['InvoiceDate'].dt.to_period('M').astype(str)\n\nproduct_cohort = product_clv.merge(\n    first_purchase_dates[['CustomerID', 'cohort']], \n    on='CustomerID', \n    how='left'\n)\n\nhero_product_list = hero_products['Description'].tolist()\nproduct_cohort['bought_hero'] = product_cohort['Description'].isin(hero_product_list)\n\nhero_adoption_2010_12 = product_cohort[product_cohort['cohort'] == '2010-12'].groupby('CustomerID')['bought_hero'].any().mean()\nhero_adoption_rest = product_cohort[product_cohort['cohort'] > '2010-12'].groupby('CustomerID')['bought_hero'].any().mean()\n\nprint('\\n=== HERO PRODUCT ADOPTION BY COHORT ===')\nprint(f'Cohort 2010-12: {hero_adoption_2010_12*100:.1f}% bought at least one hero product')\nprint(f'Rest cohorts:   {hero_adoption_rest*100:.1f}%')\nprint(f'Difference:     {(hero_adoption_2010_12 - hero_adoption_rest)*100:+.1f}pp')\n\nhero_by_segment = product_cohort[product_cohort['bought_hero']].groupby('Segment')['CustomerID'].nunique()\ntotal_by_segment = product_cohort.groupby('Segment')['CustomerID'].nunique()\nhero_penetration = (hero_by_segment / total_by_segment * 100).round(1)\n\nprint('\\n=== HERO PRODUCT PENETRATION BY SEGMENT ===')\nprint(hero_penetration.sort_values(ascending=False))\n\n# ============================================================================\n## 8. NOTEBOOK SUMMARY\n# ============================================================================\n\nprint('\\n' + '='*70)\nprint('ðŸ“Š PRODUCT-MARKET FIT ANALYSIS - COMPLETED')\nprint('='*70)\n\ntotal_products = retail_clean['Description'].nunique()\navg_repurchase = repurchase_filtered['repurchase_rate'].mean()\nhero_count = len(hero_products)\n\nprint(f\"\"\"\nKEY METRICS:\nâ€¢ Total products analyzed: {total_products:,}\nâ€¢ Average repurchase rate (eligible products): {avg_repurchase:.1f}%\nâ€¢ Hero products identified: {hero_count}\nâ€¢ Hero product revenue contribution: â‚¬{hero_revenue:,.0f} ({hero_pct:.1f}% of total revenue)\n\nKEY FINDINGS:\n1. Hero products (top {hero_count}) combine high revenue and high repurchase rates.\n2. Cohort 2010-12 has {(hero_adoption_2010_12/hero_adoption_rest):.1f}x higher hero product adoption.\n3. Champions segment shows hero product penetration of {hero_penetration.get('Champions', 0):.1f}% vs {hero_penetration.get('Lost', 0):.1f}% for Lost.\n4. Product differentiation exists: Champions and At-Risk buy different product mixes.\n\nIMPLICATIONS:\nâ†’ Priority #1: Push hero products in onboarding flows to mimic 2010-12 cohort behavior.\nâ†’ Priority #2: Design bundles and offers around hero products for New and Potential segments.\nâ†’ Priority #3: Investigate why At-Risk customers under-index on hero products.\nâ†’ Priority #4: Use hero products as anchors for acquisition and retention campaigns.\n\n\"\"\")\n\nprint('='*70 + '\\n')\n\nhero_products.to_csv('hero_products.csv', index=False)\nprint('âœ… Saved hero_products.csv for reference')\n","metadata":{},"cell_type":"code","id":"38a6c0d9-cb01-4e4d-8dcb-40ec971d0590","outputs":[],"execution_count":null}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (User venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}