{"cells":[{"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuración de visualización\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\npd.set_option('display.width', None)\n\n# ============================================================================\n# 00_DATA_CLEANING_EDA.ipynb\n# ============================================================================\n\n## 1. INITIAL DATA INSPECTION\nretail = pd.read_csv('online_retail.csv', parse_dates=['InvoiceDate'])\n\nprint(\"=\"*70)\nprint(\"DATA QUALITY ASSESSMENT\")\nprint(\"=\"*70)\n\nprint(f\"\\nDataset shape: {retail.shape}\")\nprint(f\"Date range: {retail['InvoiceDate'].min()} to {retail['InvoiceDate'].max()}\")\nprint(f\"Unique customers: {retail['CustomerID'].nunique():,}\")\nprint(f\"Unique products: {retail['StockCode'].nunique():,}\")\n\n## 2. MISSING VALUES ANALYSIS\n\nprint(\"\\n=== MISSING VALUES ===\")\nmissing= retail.isna().sum()\nmissing_pct= (missing/len(retail))*100\nmissing_df= pd.DataFrame({\n    'Missing' : missing, \n    'Percentage' : missing_pct\n}).sort_values('Percentage',ascending=False)\nprint(missing_df)\n\n# BUSINESS DECISION: \n# CustomerID missing (X%) → REMOVE (can't analyze without customer)\n# Description missing (Y%) → KEEP (can use StockCode)\n\n# DATA QUALITY ISSUES\nprint('\\n=== DATA QUALITY ISSUES ===')\n\n# Issue 1: Negative quantities (returns)\nreturns = retail[retail['Quantity']<0]\nprint(f'\\n Returns/Cancellations: {len(returns):,} ({len(returns)/len(retail)*100:.1f}%)')\n# Decision: Separate analysis or exclude\n\n# Issue 2: Zero/negative prices\nnegative_price = retail[retail['UnitPrice']<=0]\nprint(f'\\n Negative Price Error: {len(negative_price):,} ({len(negative_price)/len(retail)*100:.1f}%)')\n# Decision: REMOVE (data errors)\n\n# Issue 3: Extreme outliers\nquantity_stats = retail['Quantity'].describe()\nprint(f'\\nQuantity stats: {quantity_stats}')\nprint(f'\\nTop 5 extreme quantites:')\nprint(retail.nlargest(5,'Quantity')[['Quantity', 'Description', 'UnitPrice']])\n\n# Issue 4: Test transactions (StockCode patterns)\n# Hacer identificacion de StockCode\n# Test length\ncond_len5 = retail['StockCode'].str.len()==5\ncond_len5_digit = retail['StockCode'].str[:5].str.isdigit()\ncond_len6 = retail['StockCode'].str.len()==6\ncond_len6_digit = retail['StockCode'].str[-1]\nis_valid_sku = cond_len5 | cond_len6\nprint(f'Stock Codes with 5 digit patterns: {cond_len6_digit}')\nprint(f'Stock Codes with 6 digit patterns: {cond_len5_digit}')\n# Decision: no clear SKU patter based on lenght and structure. I am keeping StockCode as-is for traceability\n\n## 4. CLEANING PIPELINE\n\nprint(\"=\"*70)\nprint(\"CLEANING PIPELINE\")\nprint(\"=\"*70)\n\nretail_clean = retail.copy()\noriginal_len = len(retail)\n\n# Step 1: 24.9% of transactions are missing CUSTOMER ID. Since my analysis focused on customer-level behavior, I am removing these rows.\nbefore = len(retail_clean)\nretail_clean = retail_clean[retail_clean['CustomerID'].notna()]\nafter = len(retail_clean)\nprint(f\"1. Removed missing Customer ID: {before - after:,} rows\")\n\n# Step 2: Remove invalid prices\nbefore = len(retail_clean)\nretail_clean = retail_clean[retail_clean['UnitPrice']>0]\nafter  = len(retail_clean)\nprint(f\"2. Removed invalid Unit Prices: {before - after:,} total removed\")\n\n# Step 3: Remove returns (or keep them for separate analysis)\nbefore = len(retail_clean)\nretail_clean = retail_clean[retail_clean['Quantity']>0]\nafter = len(retail_clean)\nprint(f\"3. Removed returns: {before - after:,} total removed\")\n\n# Step 4: Remove test codes: recalculate test_codes/test description from retail_clean\nbefore = len(retail_clean)\ntest_codes = retail_clean['StockCode'].str.contains('TEST|BANK|POST|DOT|AMAZONFEE', na=False)\ntest_description = retail_clean['Description'].str.contains('TEST|BANK|POST|DOT|AMAZONFEE', na=False, case = False)\n\nprint(f'\\nTest/Administrative descriptions: {len(retail_clean[test_description]):,}')\nretail_clean = retail_clean[~test_codes & ~test_description]\nafter  = len(retail_clean)\nprint(f\"4. Removed test codes and test descriptions: {before - after:,} total removed\")\nprint( f\" Original rows: {original_len}\")\nprint( f\" Cleaned rows: {len(retail_clean)}\")\nprint( f\" Total removed; {original_len - len(retail_clean)}\")\n\n# 5. CREATE DERIVED COLUMNS\nretail_clean['Revenue'] = retail_clean['Quantity'] * retail_clean['UnitPrice']\nretail_clean['Year'] = retail_clean['InvoiceDate'].dt.year\nretail_clean['Month']= retail_clean['InvoiceDate'].dt.month\nretail_clean['DayOfWeek']= retail_clean['InvoiceDate'].dt.dayofweek\nretail_clean['Hour']= retail_clean['InvoiceDate'].dt.hour\n\n\n# 6. FINAL DATA SET REVIEW\nprint(\"\\n\" + \"=\"*70)\nprint(\"CLEANED DATASET SUMMARY\")\nprint(\"=\"*70)\n\nprint(f\"Original dataset: {original_len:,}\")\nprint(\n    f\"Cleaned dataset: {len(retail_clean):,} \"\n    f\"({(len(retail_clean) / original_len * 100):.1f}%)\"\n)\nprint(f\"Total removed: {original_len - len(retail_clean):,}\")\nprint(f\"Customers: {retail_clean['CustomerID'].nunique():,} unique CustomerID\")\nprint(f\"Products: {retail_clean['StockCode'].nunique():,} unique StockCode\")\nprint(f\"Date range: {retail_clean['InvoiceDate'].min()} to {retail_clean['InvoiceDate'].max()}\")\nprint(f\"Total revenue: {retail_clean['Revenue'].sum():,.2f}€\")\n\n## 7. VISUAL REPRESENTATIONS\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Revenue over time\ndaily_revenue = retail_clean.groupby(retail_clean['InvoiceDate'].dt.date)['Revenue']\ndaily_revenue.plot(ax=axes[0,0])\naxes[0,0].set_title('Daily Revenue Trend')\naxes[0,0].set_xlabel('Date')\naxes[0,0].set_ylabel('Revenue (€)')\n\n\n# 2. Top 10 countries\nretail_clean.groupby('Country')['Revenue'].sum().nlargest(10).plot(kind='barh',ax=axes[0,1])\naxes[0,1].set_title('Top 10 countries by revenue')\naxes[0,1].set_xlabel('Countries')\naxes[0,1].set_ylabel('Revenue (€)')\n\n\n# 3. Revenue distribution by client\ncustomer_revenue = retail_clean.groupby('CustomerID')['Revenue'].sum()\ncustomer_revenue.hist(bins=50, ax=axes[1,0])\naxes[1,0].set_title('Revenue distribution by client')\naxes[1,0].set_xlabel('Revenue (€)')\naxes[1,0].set_ylabel('Number of clients')\n\n\n# 4. Products by transaction size\nproducts_per_transaction = retail_clean.groupby('InvoiceNo').size()\nproducts_per_transaction.hist(bins=50, ax=axes[1,1])\n\naxes[1,1].set_title('Product per transaction')\naxes[1,1].set_xlabel('Number of Products')\n\n\nplt.tight_layout()\nplt.show()\n\n## 8. SAVED CLEAN DATA\n\nretail_clean.to_csv('online_retail_clean.csv', index=False)\nprint(f'\\n Cleaned data base saved to data/online_retail_clean.csv')\n","metadata":{},"cell_type":"code","id":"bdbaa9ef-1b42-4fdc-b15e-0097f60ee0ec","outputs":[],"execution_count":null}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (User venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}